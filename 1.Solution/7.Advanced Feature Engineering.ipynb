{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chsuJgJz7j6b",
   "metadata": {
    "id": "chsuJgJz7j6b"
   },
   "source": [
    "<br>\n",
    "\n",
    "### <span style='color:red;'><b>Note :</b></span> Majority of the Feature Engineering in this section is inspired from <a href='https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600'>this</a> competition winning kernel.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9741cd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1623668579235,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "0d9741cd"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "JCYsutppzb2T",
   "metadata": {
    "executionInfo": {
     "elapsed": 8665,
     "status": "ok",
     "timestamp": 1623668588728,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "JCYsutppzb2T"
   },
   "outputs": [],
   "source": [
    "# Loading the feature engineered train and test dataset\n",
    "\n",
    "train_data = pd.read_pickle('basic_fe_train.pkl')\n",
    "test_data = pd.read_pickle('basic_fe_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "MweOS8sRzhow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1623668588729,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "MweOS8sRzhow",
    "outputId": "d48565e3-8e33-4ea8-dfb8-b379e3b4246d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      "\n",
      " Train Data Shape : (590538, 208) \n",
      "\n",
      "\n",
      " Test Data Shape : (506691, 207) \n",
      "\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*35)\n",
    "print(\"\\n Train Data Shape : {} \\n\".format(train_data.shape))\n",
    "print(\"\\n Test Data Shape : {} \\n\".format(test_data.shape))\n",
    "print(\"*\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3HAMJ9h6l66",
   "metadata": {
    "id": "g3HAMJ9h6l66"
   },
   "source": [
    "## Utility Functions\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1kot2rZmws2c",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623668588729,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "1kot2rZmws2c"
   },
   "outputs": [],
   "source": [
    "def cat_num_features(df):\n",
    "    \n",
    "    '''\n",
    "        Utility Function to get the names of Categorical Features and \n",
    "        Numerical Features of the given Dataset.\n",
    "    '''\n",
    "    \n",
    "    catf = []\n",
    "    numf = []\n",
    "    \n",
    "    catf = [\n",
    "            'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', \n",
    "            'card6', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', \n",
    "            'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'DeviceType', 'DeviceInfo',\n",
    "            'TransactionWD', 'card1_div_1000', 'card2_div_10', 'P_parent_domain', \n",
    "            'P_domain_name', 'P_top_level_domain', 'R_parent_domain', 'R_domain_name', \n",
    "            'R_top_level_domain', 'device_name', 'device_version', 'os_name', 'os_version', \n",
    "            'screen_width', 'screen_height', 'card_intr1', 'card_intr2', 'card1_addr1', \n",
    "            'card1_addr2', 'card2_addr1', 'card2_addr2', 'card3_addr1', 'card3_addr2', \n",
    "            'card5_addr1', 'card5_addr2', 'card6_addr1', 'card6_addr2', 'ProductCD_addr1', \n",
    "            'ProductCD_addr2', 'card1_ProductCD', 'card2_ProductCD', 'card5_ProductCD', \n",
    "            'card6_ProductCD', 'addr1_P_emaildomain', 'card1_P_emaildoman', 'card1_addr1_P_emaildomain',\n",
    "            'uid1', 'uid2'\n",
    "            ]\n",
    "\n",
    "    catf+=['id_'+str(i) for i in range(12,39)]\n",
    "\n",
    "\n",
    "    # Updating the Categorical Feature Names List based on the columns present in the dataframe\n",
    "    catf = [feature for feature in catf if feature in df.columns]\n",
    "    numf = [feature for feature in df.columns if feature not in catf and not feature == 'isFraud']\n",
    "    \n",
    "    return (catf, numf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BvRWrOwoSsZY",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623668588730,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "BvRWrOwoSsZY"
   },
   "outputs": [],
   "source": [
    "def label_encode(X_train, X_test, catf):\n",
    "  \n",
    "  '''\n",
    "    Utility Function to Encode Categorical Features.\n",
    "  '''\n",
    "\n",
    "  for f in catf:\n",
    "    \n",
    "    X_train[f] = X_train[f].astype(str)\n",
    "    X_test[f] = X_test[f].astype(str)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[f])\n",
    "    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    X_train[f] = le.transform(X_train[f])\n",
    "    \n",
    "    # Manually Encoding the test and Test Dataset so as to avoid error for any category which is not present in train set\n",
    "    \n",
    "    # All the categories which are not present in train datset are encoded as -1    \n",
    "    X_test[f] = [-1 if mapping.get(v, -1)==-1 else mapping[v] for v in X_test[f].values ]\n",
    "\n",
    "  return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132477c4",
   "metadata": {
    "id": "132477c4"
   },
   "source": [
    "### Encoding Functions\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62fa566",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623668588730,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "a62fa566"
   },
   "outputs": [],
   "source": [
    "def frequency_encode(train_df, test_df, features):\n",
    "\n",
    "  '''\n",
    "    Utility Function to perform frequency encoding for a feature.\n",
    "  '''\n",
    "\n",
    "  for f in features:\n",
    "      \n",
    "      value_count_dict = train_df[f].value_counts(dropna=True, normalize=True).to_dict()\n",
    "      name = f+'_FE'  \n",
    "      train_df[name] = train_df[f].map(value_count_dict) \n",
    "      \n",
    "      # Manually Encoding the feature in test dataset so as to avoid error for a feature value which is not in train set\n",
    "      \n",
    "      # Assigning -1 to all the values of the test feature which are not in train set\n",
    "      test_df[name] = [value_count_dict.get(val, -1) for val in test_df[f].values]\n",
    "\n",
    "      print(name)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda\n",
    "\n",
    "def feature_aggregation1(features, uids, train_df, test_df, aggregations=['mean']):\n",
    "    \n",
    "    '''\n",
    "      Utility Function to perform aggregation of a given feature with uid for given statistic.\n",
    "    '''\n",
    "\n",
    "    for f in features:  \n",
    "        for uid in uids:\n",
    "            for agg_type in aggregations:\n",
    "                \n",
    "                name = f+'_'+uid+'_'+agg_type\n",
    "\n",
    "                temp_df = train_df.groupby([uid])[f].agg([agg_type]).reset_index().rename(columns={agg_type: name})\n",
    "\n",
    "                temp_df.index = list(temp_df[uid])\n",
    "                temp_df = temp_df[name].to_dict()   \n",
    "\n",
    "                train_df[name] = train_df[uid].map(temp_df)\n",
    "\n",
    "                # Manually Encoding the feature in test dataset so as to avoid error for a feature value which is not in train set\n",
    "        \n",
    "                # Assigning -1 to all the values of the test feature which are not in train set\n",
    "                test_df[name] = [temp_df.get(uid, -1) for uid in test_df[uid].values]\n",
    "\n",
    "                print(name)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def feature_aggregation2(features, uids, train_df, test_df):\n",
    "  '''\n",
    "    Utility Function to perform Aggregation based on the number of unique values present in a feature.\n",
    "  '''\n",
    "\n",
    "  for f in features:  \n",
    "      for uid in uids:\n",
    "\n",
    "          temp_df = train_df[[uid]+[f]]\n",
    "          \n",
    "          mp = temp_df.groupby(uid)[f].agg(['nunique'])['nunique'].to_dict()\n",
    "          \n",
    "          name = uid+'_'+f+'_ct'\n",
    "\n",
    "          train_df[name] = train_df[uid].map(mp)\n",
    "\n",
    "          # Manually Encoding the feature in test dataset so as to avoid error for a feature value which is not in train set\n",
    "      \n",
    "          # Assigning -1 to all the values of the test feature which are not in train set\n",
    "          test_df[name] = [mp.get(uid, -1) for uid in test_df[uid].values]\n",
    "\n",
    "          print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lWPaUlzh8YGr",
   "metadata": {
    "id": "lWPaUlzh8YGr"
   },
   "source": [
    "## Data Preparation\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27733b6",
   "metadata": {
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1623668589559,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "b27733b6"
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['isFraud'], axis=1)\n",
    "y_train = train_data['isFraud']\n",
    "\n",
    "X_test = test_data\n",
    "\n",
    "del train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "W7znSr1bwsz5",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1623668589560,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "W7znSr1bwsz5"
   },
   "outputs": [],
   "source": [
    "# Storing Categorical and Numerical Feature Names \n",
    "\n",
    "catf, numf = cat_num_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "yINKR0_ZwoIv",
   "metadata": {
    "executionInfo": {
     "elapsed": 76108,
     "status": "ok",
     "timestamp": 1623668665666,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "yINKR0_ZwoIv"
   },
   "outputs": [],
   "source": [
    "# Encoding the Categorical Features\n",
    "\n",
    "X_train[catf] = X_train[catf].fillna('missing')\n",
    "X_test[catf] = X_test[catf].fillna('missing')\n",
    "\n",
    "X_train, X_test = label_encode(X_train, X_test, catf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905365ac",
   "metadata": {
    "id": "905365ac"
   },
   "source": [
    "## Feature Engineering\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "VwYY_OItxfyW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9562,
     "status": "ok",
     "timestamp": 1623668675202,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "VwYY_OItxfyW",
    "outputId": "503d4efb-7bf7-4f6c-aa4d-647b1345c7bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr1_FE\n",
      "card1_FE\n",
      "card2_FE\n",
      "card3_FE\n",
      "P_emaildomain_FE\n",
      "card1_addr1_FE\n",
      "card1_addr1_P_emaildomain_FE\n",
      "TransactionAmt_card1_mean\n",
      "TransactionAmt_card1_std\n",
      "TransactionAmt_card1_addr1_mean\n",
      "TransactionAmt_card1_addr1_std\n",
      "TransactionAmt_card1_addr1_P_emaildomain_mean\n",
      "TransactionAmt_card1_addr1_P_emaildomain_std\n",
      "D9_card1_mean\n",
      "D9_card1_std\n",
      "D9_card1_addr1_mean\n",
      "D9_card1_addr1_std\n",
      "D9_card1_addr1_P_emaildomain_mean\n",
      "D9_card1_addr1_P_emaildomain_std\n",
      "D11_card1_mean\n",
      "D11_card1_std\n",
      "D11_card1_addr1_mean\n",
      "D11_card1_addr1_std\n",
      "D11_card1_addr1_P_emaildomain_mean\n",
      "D11_card1_addr1_P_emaildomain_std\n"
     ]
    }
   ],
   "source": [
    "# Frequency Encoding\n",
    "\n",
    "frequency_encode(X_train,X_test,['addr1','card1','card2','card3','P_emaildomain'])\n",
    "frequency_encode(X_train,X_test,['card1_addr1','card1_addr1_P_emaildomain'])\n",
    "\n",
    "\n",
    "# Feature Aggregation\n",
    "\n",
    "feature_aggregation1(['TransactionAmt','D9','D11'],['card1','card1_addr1','card1_addr1_P_emaildomain'],X_train, X_test, ['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "MWCNioFz8tIp",
   "metadata": {
    "executionInfo": {
     "elapsed": 2198,
     "status": "ok",
     "timestamp": 1623668677385,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "MWCNioFz8tIp"
   },
   "outputs": [],
   "source": [
    "# Adding Month Feature, this will also be used while making final predictions\n",
    "\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "X_train['DT_M'] = X_train['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "X_train['DT_M'] = (X_train['DT_M'].dt.year-2017)*12 + X_train['DT_M'].dt.month \n",
    "\n",
    "X_test['DT_M'] = X_test['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "X_test['DT_M'] = (X_test['DT_M'].dt.year-2017)*12 + X_test['DT_M'].dt.month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "TSICYFhHQ2d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48162,
     "status": "ok",
     "timestamp": 1623668725540,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "TSICYFhHQ2d0",
    "outputId": "73f51a30-d68c-4b59-a92c-bb4537ce4229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid1_FE\n",
      "uid2_FE\n",
      "TransactionAmt_uid1_mean\n",
      "TransactionAmt_uid1_std\n",
      "TransactionAmt_uid2_mean\n",
      "TransactionAmt_uid2_std\n",
      "D4_uid1_mean\n",
      "D4_uid1_std\n",
      "D4_uid2_mean\n",
      "D4_uid2_std\n",
      "D9_uid1_mean\n",
      "D9_uid1_std\n",
      "D9_uid2_mean\n",
      "D9_uid2_std\n",
      "D10_uid1_mean\n",
      "D10_uid1_std\n",
      "D10_uid2_mean\n",
      "D10_uid2_std\n",
      "D15_uid1_mean\n",
      "D15_uid1_std\n",
      "D15_uid2_mean\n",
      "D15_uid2_std\n",
      "C1_uid1_mean\n",
      "C1_uid2_mean\n",
      "C2_uid1_mean\n",
      "C2_uid2_mean\n",
      "C4_uid1_mean\n",
      "C4_uid2_mean\n",
      "C5_uid1_mean\n",
      "C5_uid2_mean\n",
      "C6_uid1_mean\n",
      "C6_uid2_mean\n",
      "C7_uid1_mean\n",
      "C7_uid2_mean\n",
      "C9_uid1_mean\n",
      "C9_uid2_mean\n",
      "C10_uid1_mean\n",
      "C10_uid2_mean\n",
      "C11_uid1_mean\n",
      "C11_uid2_mean\n",
      "C12_uid1_mean\n",
      "C12_uid2_mean\n",
      "C13_uid1_mean\n",
      "C13_uid2_mean\n",
      "C14_uid1_mean\n",
      "C14_uid2_mean\n",
      "M1_uid1_mean\n",
      "M1_uid2_mean\n",
      "M2_uid1_mean\n",
      "M2_uid2_mean\n",
      "M3_uid1_mean\n",
      "M3_uid2_mean\n",
      "M4_uid1_mean\n",
      "M4_uid2_mean\n",
      "M5_uid1_mean\n",
      "M5_uid2_mean\n",
      "M6_uid1_mean\n",
      "M6_uid2_mean\n",
      "M7_uid1_mean\n",
      "M7_uid2_mean\n",
      "M8_uid1_mean\n",
      "M8_uid2_mean\n",
      "M9_uid1_mean\n",
      "M9_uid2_mean\n",
      "C14_uid1_std\n",
      "C14_uid2_std\n",
      "uid1_P_emaildomain_ct\n",
      "uid2_P_emaildomain_ct\n",
      "uid1_dist1_ct\n",
      "uid2_dist1_ct\n",
      "uid1_DT_M_ct\n",
      "uid2_DT_M_ct\n",
      "uid1_id_02_ct\n",
      "uid2_id_02_ct\n",
      "uid1_cents_ct\n",
      "uid2_cents_ct\n",
      "uid1_V127_ct\n",
      "uid2_V127_ct\n",
      "uid1_V307_ct\n",
      "uid2_V307_ct\n"
     ]
    }
   ],
   "source": [
    "# FREQUENCY ENCODE UID\n",
    "\n",
    "frequency_encode(X_train,X_test,['uid1', 'uid2'])\n",
    "\n",
    "\n",
    "# AGGREGATE UID\n",
    "\n",
    "feature_aggregation1(['TransactionAmt','D4','D9','D10','D15'],['uid1', 'uid2'],X_train, X_test,['mean','std'])\n",
    "feature_aggregation1(['C'+str(i) for i in range(1,15) if 'C'+str(i) in X_train.columns],['uid1', 'uid2'],X_train,X_test,['mean'])\n",
    "feature_aggregation1(['M'+str(i) for i in range(1,10) if 'M'+str(i) in X_train.columns],['uid1', 'uid2'], X_train, X_test,['mean'])\n",
    "feature_aggregation1(['C14'],['uid1', 'uid2'],X_train,X_test,['std'])\n",
    "\n",
    "\n",
    "feature_aggregation2(['P_emaildomain','dist1','DT_M','id_02','cents'], ['uid1', 'uid2'],X_train,X_test)\n",
    "feature_aggregation2(['V127','V307'],['uid1', 'uid2'],X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "PINEY_qQQC0X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1623668725541,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "PINEY_qQQC0X",
    "outputId": "e95e1924-df25-45f2-9b64-c611a7b8f88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outsider15\n"
     ]
    }
   ],
   "source": [
    "# New Feature \n",
    "\n",
    "X_train['outsider15'] = (np.abs(X_train.D1-X_train.D15)>3).astype('int8')\n",
    "X_test['outsider15'] = (np.abs(X_test.D1-X_test.D15)>3).astype('int8')\n",
    "print('outsider15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bm8K322Gy8k",
   "metadata": {
    "executionInfo": {
     "elapsed": 1805,
     "status": "ok",
     "timestamp": 1623668727341,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "1bm8K322Gy8k"
   },
   "outputs": [],
   "source": [
    "X_train.drop(['uid1', 'uid2'], axis=1, inplace=True)\n",
    "X_test.drop(['uid1', 'uid2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tyUblVkz1cRI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1623668727351,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "tyUblVkz1cRI",
    "outputId": "5e04eb31-84ea-4609-82d4-482eab0c55e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      "\n",
      " Train Data Shape : (590538, 312) \n",
      "\n",
      "\n",
      " Test Data Shape : (506691, 312) \n",
      "\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*35)\n",
    "print(\"\\n Train Data Shape : {} \\n\".format(X_train.shape))\n",
    "print(\"\\n Test Data Shape : {} \\n\".format(X_test.shape))\n",
    "print(\"*\"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ypGSfidtQLju",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1623668727354,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "ypGSfidtQLju"
   },
   "outputs": [],
   "source": [
    "X_train['isFraud'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7706d0",
   "metadata": {
    "executionInfo": {
     "elapsed": 16396,
     "status": "ok",
     "timestamp": 1623668743732,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "dd7706d0"
   },
   "outputs": [],
   "source": [
    "# Saving the Feature Engineered Datasets\n",
    "\n",
    "X_train.to_pickle('advanced_fe_train.pkl')\n",
    "X_test.to_pickle('advanced_fe_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "7.Advanced Feature Engineering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
