{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1623831192635,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "lyGprlSx6Msw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623831193103,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "P-ruwa563SOh"
   },
   "outputs": [],
   "source": [
    "# Global Paths\n",
    "\n",
    "clf_path = './Classifiers/'\n",
    "input_path = './Input/'\n",
    "mapping_path = './Mappings/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK0t6-Wj3SOi"
   },
   "source": [
    "### Utility Functions\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1623831193103,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "pBkkeQ_I6Ms2"
   },
   "outputs": [],
   "source": [
    "def parent_device_name(df):\n",
    "  '''\n",
    "    Utility Function to map deice name to its parent company.\n",
    "  '''\n",
    "    \n",
    "  \n",
    "  if(df['device_name'].isna().all()):\n",
    "    return df\n",
    "\n",
    "  df.loc[df['device_name'].str.contains('SM', na=True), 'device_name'] = 'Samsung'\n",
    "  df.loc[df['device_name'].str.contains('SAMSUNG', na=True), 'device_name'] = 'Samsung'\n",
    "  df.loc[df['device_name'].str.contains('GT-', na=True), 'device_name'] = 'Samsung'\n",
    "  df.loc[df['device_name'].str.contains('Moto G', na=True), 'device_name'] = 'Motorola'\n",
    "  df.loc[df['device_name'].str.contains('Moto', na=True), 'device_name'] = 'Motorola'\n",
    "  df.loc[df['device_name'].str.contains('moto', na=True), 'device_name'] = 'Motorola'\n",
    "  df.loc[df['device_name'].str.contains('LG-', na=True), 'device_name'] = 'LG'\n",
    "  df.loc[df['device_name'].str.contains('rv:', na=True), 'device_name'] = 'RV'\n",
    "  df.loc[df['device_name'].str.contains('HUAWEI', na=True), 'device_name'] = 'Huawei'\n",
    "  df.loc[df['device_name'].str.contains('ALE-', na=True), 'device_name'] = 'Huawei'\n",
    "  df.loc[df['device_name'].str.contains('-L', na=True), 'device_name'] = 'Huawei'\n",
    "  df.loc[df['device_name'].str.contains('Blade', na=True), 'device_name'] = 'ZTE'\n",
    "  df.loc[df['device_name'].str.contains('BLADE', na=True), 'device_name'] = 'ZTE'\n",
    "  df.loc[df['device_name'].str.contains('Linux', na=True), 'device_name'] = 'Linux'\n",
    "  df.loc[df['device_name'].str.contains('XT', na=True), 'device_name'] = 'Sony'\n",
    "  df.loc[df['device_name'].str.contains('HTC', na=True), 'device_name'] = 'HTC'\n",
    "  df.loc[df['device_name'].str.contains('ASUS', na=True), 'device_name'] = 'Asus'\n",
    "  df.loc[df.device_name.isin(df.device_name.value_counts()[df.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1623832478997,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "6jwqaKOE6Ms3"
   },
   "outputs": [],
   "source": [
    "def basic_feature_engineering(testdata):\n",
    "    \n",
    "    testdata['TransactionMT'] = (testdata['TransactionDT']//60)%60\n",
    "    testdata['TransactionMT_X'] = np.sin(2.*np.pi*testdata['TransactionMT']/60.)\n",
    "    testdata['TransactionMT_Y'] = np.cos(2.*np.pi*testdata['TransactionMT']/60.)\n",
    "    \n",
    "    testdata['TransactionHR'] = (testdata['TransactionDT']//3600)%24\n",
    "    testdata['TransactionHR_X'] = np.sin(2.*np.pi*testdata['TransactionHR']/24.)\n",
    "    testdata['TransactionHR_Y'] = np.cos(2.*np.pi*testdata['TransactionHR']/24.)\n",
    "    \n",
    "    testdata['TransactionDay'] = testdata['TransactionDT']//(24*3600)\n",
    "    \n",
    "    testdata['TransactionWD'] = (testdata['TransactionDT']//(24*3600))%7\n",
    "    \n",
    "    testdata_amt_whole = [int(str(a).split('.')[0]) for a in testdata['TransactionAmt'].values]\n",
    "    testdata_amt_decimal = [int(str(a).split('.')[1]) for a in testdata['TransactionAmt'].values]\n",
    "    testdata['dollars'] = testdata_amt_whole\n",
    "    testdata['cents'] = testdata_amt_decimal\n",
    "    \n",
    "    testdata['TransactionAmt_log'] = np.log(testdata['TransactionAmt'])\n",
    "\n",
    "    testdata['card1_div_1000'] = testdata['card1']//1000\n",
    "\n",
    "    testdata['card2_div_10'] = testdata['card2']//10\n",
    "\n",
    "\n",
    "    parent_domain = {'gmail.com':'gmail', 'outlook.com':'microsoft', \n",
    "                     'yahoo.com':'yahoo', 'mail.com':'mail', 'anonymous.com':'anonymous', \n",
    "                     'hotmail.com':'microsoft', 'verizon.net':'verizon', 'aol.com':'aol', \n",
    "                     'me.com':'apple', 'comcast.net':'comcast', 'optonline.net':'optimum', \n",
    "                     'cox.net':'cox', 'charter.net':'spectrum', 'rocketmail.com':'yahoo', \n",
    "                     'prodigy.net.mx':'AT&T', 'embarqmail.com':'century_link', 'icloud.com':'apple', \n",
    "                     'live.com.mx':'microsoft', 'gmail':'gmail', 'live.com':'microsoft', \n",
    "                     'att.net':'AT&T', 'juno.com':'juno', 'ymail.com':'yahoo', \n",
    "                     'sbcglobal.net':'sbcglobal', 'bellsouth.net':'AT&T', 'msn.com':'microsoft', \n",
    "                     'q.com':'century_link','yahoo.com.mx':'yahoo', 'centurylink.net':'century_link',  \n",
    "                     'servicios-ta.com':'asur','earthlink.net':'earthlink', 'hotmail.es':'microsoft', \n",
    "                     'cfl.rr.com':'spectrum', 'roadrunner.com':'spectrum','netzero.net':'netzero', \n",
    "                     'gmx.de':'gmx','suddenlink.net':'suddenlink','frontiernet.net':'frontier', \n",
    "                     'windstream.net':'windstream','frontier.com':'frontier','outlook.es':'microsoft', \n",
    "                     'mac.com':'apple','netzero.com':'netzero','aim.com':'aol', \n",
    "                     'web.de':'web_de','twc.com':'whois','cableone.net':'sparklight', \n",
    "                     'yahoo.fr':'yahoo','yahoo.de':'yahoo','yahoo.es':'yahoo', 'scranton.edu':'scranton', \n",
    "                     'sc.rr.com':'sc_rr','ptd.net':'ptd','live.fr':'microsoft', \n",
    "                     'yahoo.co.uk':'yahoo','hotmail.fr':'microsoft','hotmail.de':'microsoft', \n",
    "                     'hotmail.co.uk':'microsoft','protonmail.com':'protonmail','yahoo.co.jp':'yahoo'}\n",
    "\n",
    "    \n",
    "    testdata_P_emaildomain = testdata['P_emaildomain']\n",
    "\n",
    "    testdata['P_parent_domain'] = [np.nan if pd.isna(domain) else parent_domain[domain] for domain in testdata_P_emaildomain] \n",
    "\n",
    "    testdata['P_domain_name'] = [np.nan if pd.isna(addrs) else addrs.split('.')[0] for addrs in testdata_P_emaildomain]\n",
    "\n",
    "    testdata['P_top_level_domain'] = [np.nan if (pd.isna(addrs)) or (len(addrs.split('.'))<=1) else '.'.join(addrs.split('.')[1:]) for addrs in testdata_P_emaildomain]\n",
    "\n",
    "    \n",
    "    \n",
    "    testdata_R_emaildomain = testdata['R_emaildomain']\n",
    "\n",
    "    testdata['R_parent_domain'] = [np.nan if pd.isna(domain) else parent_domain[domain] for domain in testdata_R_emaildomain] \n",
    "\n",
    "    testdata['R_domain_name'] = [np.nan if pd.isna(addrs) else addrs.split('.')[0] for addrs in testdata_R_emaildomain]\n",
    "\n",
    "    testdata['R_top_level_domain'] = [np.nan if (pd.isna(addrs)) or (len(addrs.split('.'))<=1) else '.'.join(addrs.split('.')[1:]) for addrs in testdata_R_emaildomain]\n",
    "    \n",
    "    testdata['device_name'] = [np.nan if pd.isna(v) else v.split('/')[0] for v in testdata['DeviceInfo'].values]\n",
    "\n",
    "    testdata['device_version'] = [np.nan if (pd.isna(v)) or (len(v.split('/'))<=1) else v.split('/')[1] for v in testdata['DeviceInfo'].values]\n",
    "\n",
    "    testdata = parent_device_name(testdata)\n",
    "    \n",
    "    testdata['os_name'] = [info if (pd.isna(info)) or (len(info.split())<=1) else ' '.join(info.split()[:-1]) for info in testdata['id_30']]\n",
    "\n",
    "    testdata['os_version'] = [np.nan if (pd.isna(info)) or (len(info.split())<=1) else info.split()[-1] for info in testdata['id_30']]\n",
    "    \n",
    "    testdata['screen_width'] = [np.nan if pd.isna(v) else v.split('x')[0] for v in testdata['id_33'].values]\n",
    "\n",
    "    testdata['screen_height'] = [np.nan if (pd.isna(v)) or len(v.split('x'))<=1 else v.split('x')[1] for v in testdata['id_33'].values]\n",
    "    \n",
    "    \n",
    "    testdata['card_intr1'] = testdata['card1_div_1000'].astype(str) + \" \" + \\\n",
    "                           testdata['card2_div_10'].astype(str) + \" \" + \\\n",
    "                           testdata['card3'].astype(str) + \" \" + \\\n",
    "                           testdata['card5'].astype(str) + \" \" + \\\n",
    "                           testdata['card6'].astype(str)\n",
    "\n",
    "\n",
    "    testdata['card_intr2'] = testdata['card1'].astype(str) + \" \" + \\\n",
    "                               testdata['card2'].astype(str) + \" \" + \\\n",
    "                               testdata['card3'].astype(str) + \" \" + \\\n",
    "                               testdata['card5'].astype(str) + \" \" + \\\n",
    "                               testdata['card6'].astype(str)\n",
    "    \n",
    "    \n",
    "    testdata['card1_addr1'] = testdata['card1'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['card1_addr2'] = testdata['card1'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['card2_addr1'] = testdata['card2'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['card2_addr2'] = testdata['card2'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['card3_addr1'] = testdata['card3'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['card3_addr2'] = testdata['card3'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['card5_addr1'] = testdata['card5'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['card5_addr2'] = testdata['card5'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['card6_addr1'] = testdata['card6'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['card6_addr2'] = testdata['card6'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['ProductCD_addr1'] = testdata['ProductCD'].astype(str)+testdata['addr1'].astype(str)\n",
    "\n",
    "    testdata['ProductCD_addr2'] = testdata['ProductCD'].astype(str)+testdata['addr2'].astype(str)\n",
    "\n",
    "    \n",
    "    testdata['card1_ProductCD'] =testdata['card1'].astype(str)+testdata['ProductCD'].astype(str)\n",
    "\n",
    "    testdata['card2_ProductCD'] =testdata['card2'].astype(str)+testdata['ProductCD'].astype(str)\n",
    "\n",
    "    testdata['card5_ProductCD'] =testdata['card5'].astype(str)+testdata['ProductCD'].astype(str)\n",
    "\n",
    "    testdata['card6_ProductCD'] = testdata['card6'].astype(str)+testdata['ProductCD'].astype(str)\n",
    "    \n",
    "    \n",
    "    testdata['addr1_P_emaildomain'] = testdata['addr1'].astype(str)+testdata['P_emaildomain'].astype(str)\n",
    "\n",
    "    testdata['card1_P_emaildoman'] = testdata['card1'].astype(str)+testdata['P_emaildomain'].astype(str)\n",
    "\n",
    "    testdata['card1_addr1_P_emaildomain'] = testdata['card1'].astype(str)+testdata['addr1_P_emaildomain'].astype(str)\n",
    "\n",
    "    \n",
    "    d_features = [\"D\"+str(i) for i in range(1,16) if \"D\"+str(i) in testdata.columns]\n",
    "\n",
    "    for f in d_features:\n",
    "        testdata[f] =  testdata[f] - testdata['TransactionDay']\n",
    "\n",
    "    \n",
    "    testdata['uid1'] = testdata['card1'].astype(str)+testdata['card2'].astype(str)+\\\n",
    "                         testdata['card3'].astype(str)+testdata['card5'].astype(str)+\\\n",
    "                         testdata['card6'].astype(str)+testdata['addr1'].astype(str)+\\\n",
    "                         testdata['P_emaildomain'].astype(str)\n",
    "\n",
    "\n",
    "    testdata['uid2'] = testdata['card1'].astype(str)+testdata['addr1_P_emaildomain'].astype(str)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623832289763,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "9s0aNahY6Ms8"
   },
   "outputs": [],
   "source": [
    "def label_encode(testdata):\n",
    "\n",
    "    with open(mapping_path+'catf.pkl', 'rb') as handle:\n",
    "        catf = pickle.load(handle)\n",
    "        \n",
    "    with open(mapping_path+'label_encoder_dict.pkl', 'rb') as handle:\n",
    "        label_encoder_mapping_dict = pickle.load(handle)\n",
    "    \n",
    "    catf = [f for f in testdata.columns if f in catf]\n",
    "\n",
    "    testdata[catf]=testdata[catf].fillna('missing')\n",
    "    \n",
    "    for f in catf:\n",
    "        testdata[f] = testdata[f].astype(str)\n",
    "        mapping = label_encoder_mapping_dict[f]\n",
    "        testdata[f] = [-1 if mapping.get(v, -1)==-1 else mapping[v] for v in testdata[f].values]\n",
    "        del mapping\n",
    "        \n",
    "    del catf, label_encoder_mapping_dict\n",
    "    \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1623832290235,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "rys0RtQr6Ms8"
   },
   "outputs": [],
   "source": [
    "def frequency_encode(testdata, frequency_encoder_dict, features):\n",
    "\n",
    "    '''\n",
    "    Utility Function to perform frequency encoding for a feature.\n",
    "    '''\n",
    "\n",
    "    for f in features:\n",
    "        value_count_dict = frequency_encoder_dict[f]\n",
    "        name = f+'_FE'        \n",
    "        testdata[name] = [value_count_dict.get(val, -1) for val in testdata[f].values]\n",
    "        \n",
    "    return testdata\n",
    "        \n",
    "    \n",
    "        \n",
    "def feature_aggregation1(features, uids, testdata, feature_aggregation1_dict, aggregations=['mean']):\n",
    "    \n",
    "    '''\n",
    "      Utility Function to perform aggregation of a given feature with uid for given statistic.\n",
    "    '''\n",
    "\n",
    "    for f in features:  \n",
    "        for uid in uids:\n",
    "            for agg_type in aggregations:\n",
    "                \n",
    "                temp_df = feature_aggregation1_dict[f][uid][agg_type]\n",
    "                \n",
    "                name = f+'_'+uid+'_'+agg_type\n",
    "\n",
    "                testdata[name] = [temp_df.get(uid, -1) for uid in testdata[uid].values]\n",
    "    \n",
    "    return testdata\n",
    "                \n",
    "def feature_aggregation2(features, uids, testdata, feature_aggregation2_dict):\n",
    "    \n",
    "    '''\n",
    "    Utility Function to perform Aggregation based on the number of unique values present in a feature.\n",
    "    '''\n",
    "\n",
    "    for f in features:  \n",
    "        for uid in uids:\n",
    "\n",
    "            mp = feature_aggregation2_dict[f][uid]\n",
    "\n",
    "            name = uid+'_'+f+'_ct'\n",
    "\n",
    "            testdata[name] = [mp.get(uid, -1) for uid in testdata[uid].values]\n",
    "\n",
    "    return testdata\n",
    "        \n",
    "\n",
    "def advanced_feature_engineering(testdata):\n",
    "\n",
    "    with open(mapping_path+'frequency_encoder_dict.pkl', 'rb') as handle:\n",
    "        frequency_encoder_dict = pickle.load(handle)\n",
    "\n",
    "    with open(mapping_path+'feature_aggregation1_dict.pkl', 'rb') as handle:\n",
    "        feature_aggregation1_dict = pickle.load(handle)\n",
    "\n",
    "    with open(mapping_path+'feature_aggregation2_dict.pkl', 'rb') as handle:\n",
    "        feature_aggregation2_dict = pickle.load(handle)\n",
    "        \n",
    "\n",
    "    testdata = frequency_encode(testdata,frequency_encoder_dict,['addr1','card1','card2','card3','P_emaildomain'])\n",
    "    testdata = frequency_encode(testdata,frequency_encoder_dict,['card1_addr1','card1_addr1_P_emaildomain'])\n",
    "\n",
    "    testdata = feature_aggregation1(['TransactionAmt','D9','D11'],['card1','card1_addr1','card1_addr1_P_emaildomain'],testdata, feature_aggregation1_dict, ['mean','std'])\n",
    "\n",
    "    START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "    testdata['DT_M'] = testdata['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    \n",
    "    testdata = frequency_encode(testdata,frequency_encoder_dict,['uid1', 'uid2'])\n",
    "\n",
    "    testdata = feature_aggregation1(['TransactionAmt','D4','D9','D10','D15'],['uid1', 'uid2'],testdata, feature_aggregation1_dict,['mean','std'])\n",
    "    testdata = feature_aggregation1(['C'+str(i) for i in range(1,15) if 'C'+str(i) in testdata.columns],['uid1', 'uid2'],testdata,feature_aggregation1_dict,['mean'])\n",
    "    testdata = feature_aggregation1(['M'+str(i) for i in range(1,10) if 'M'+str(i) in testdata.columns],['uid1', 'uid2'], testdata, feature_aggregation1_dict,['mean'])\n",
    "    testdata = feature_aggregation1(['C14'],['uid1', 'uid2'],testdata,feature_aggregation1_dict,['std'])\n",
    "\n",
    "    testdata = feature_aggregation2(['P_emaildomain','dist1','DT_M','id_02','cents'], ['uid1', 'uid2'],testdata,feature_aggregation2_dict)\n",
    "    testdata = feature_aggregation2(['V127','V307'],['uid1', 'uid2'],testdata,feature_aggregation2_dict)\n",
    "\n",
    "    testdata['outsider15'] = (np.abs(testdata.D1-testdata.D15)>3).astype('int8')\n",
    "    \n",
    "    testdata.drop(['uid1', 'uid2'], axis=1, inplace=True)\n",
    "    \n",
    "    del frequency_encoder_dict, feature_aggregation1_dict, feature_aggregation2_dict\n",
    "    \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623832290236,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "gxjg_tBl3SOs"
   },
   "outputs": [],
   "source": [
    "def preprocess(testdata):\n",
    "    \n",
    "    placeholder_file = pd.read_csv(input_path+'placeholder_file.csv')\n",
    "    \n",
    "    testdata.columns = placeholder_file.columns.values\n",
    "    \n",
    "    data = pd.DataFrame(testdata.values, columns = placeholder_file.columns)\n",
    "    \n",
    "    data = data.astype(testdata.dtypes.to_dict()) \n",
    "\n",
    "    testdata = data\n",
    "\n",
    "    del placeholder_file, data\n",
    "\n",
    "    with open(mapping_path+'drop_features.pkl', 'rb') as handle:\n",
    "        features_to_drop = pickle.load(handle)\n",
    "\n",
    "    testdata.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    testdata = basic_feature_engineering(testdata)\n",
    "\n",
    "    testdata = label_encode(testdata)\n",
    "\n",
    "    testdata = advanced_feature_engineering(testdata)\n",
    "        \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84WZf3tm3SOs"
   },
   "source": [
    "### Prediction\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1623832532135,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "kqochbMj6Ms9"
   },
   "outputs": [],
   "source": [
    "def predict_proba(testdata):\n",
    "    \n",
    "    '''\n",
    "        Utility function to predict the probability of a transaction being fraudulent.\n",
    "    '''\n",
    "\n",
    "    testdata = preprocess(testdata)\n",
    "\n",
    "\n",
    "    with open(mapping_path+'covariate_shifted_features.pkl', 'rb') as handle:\n",
    "      features_with_covariate_shift = pickle.load(handle)\n",
    "\n",
    "    cols = [f for f in testdata if f not in features_with_covariate_shift]\n",
    "\n",
    "    with open(clf_path+'clf_0.pkl', 'rb') as handle:\n",
    "        clf_0 = pickle.load(handle)\n",
    "\n",
    "    with open(clf_path+'clf_1.pkl', 'rb') as handle:\n",
    "        clf_1 = pickle.load(handle)\n",
    "\n",
    "    with open(clf_path+'clf_2.pkl', 'rb') as handle:\n",
    "        clf_2 = pickle.load(handle)\n",
    "\n",
    "    with open(clf_path+'clf_3.pkl', 'rb') as handle:\n",
    "        clf_3 = pickle.load(handle)\n",
    "\n",
    "    with open(clf_path+'clf_4.pkl', 'rb') as handle:\n",
    "        clf_4 = pickle.load(handle)\n",
    "\n",
    "    with open(clf_path+'clf_5.pkl', 'rb') as handle:\n",
    "        clf_5 = pickle.load(handle)\n",
    "\n",
    "    classifiers = [clf_0, clf_1, clf_2, clf_3, clf_4, clf_5]\n",
    "\n",
    "    test_proba = np.zeros(len(testdata))\n",
    "\n",
    "    for clf in classifiers:\n",
    "        test_proba+=clf.predict_proba(testdata[cols])[:,1]/len(classifiers)\n",
    "\n",
    "    del clf_0, clf_1, clf_2, clf_3, clf_4, clf_5, features_with_covariate_shift, cols\n",
    "\n",
    "    print(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('./Uploads/sample_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3484,
     "status": "ok",
     "timestamp": 1623832537990,
     "user": {
      "displayName": "Priyank Mishra",
      "photoUrl": "",
      "userId": "18008032652400229851"
     },
     "user_tz": -330
    },
    "id": "31fAt9623SOu",
    "outputId": "13c0b6be-72da-4c4c-9aba-db5639d5511e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:52] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:52] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[14:27:52] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:52] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[14:27:53] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:53] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[14:27:54] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:54] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[14:27:55] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:55] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[14:27:56] WARNING: ../src/gbm/gbtree.cc:355: Loading from a raw memory buffer on CPU only machine.  Changing tree_method to hist.\n",
      "[14:27:56] WARNING: ../src/learner.cc:223: No visible GPU is found, setting `gpu_id` to -1\n",
      "[9.83923339e-04 2.33265445e-03 6.34102934e-03 2.59777685e-03\n",
      " 1.71841210e-03 1.26519950e-03 2.03230508e-02 2.49634819e-02\n",
      " 3.33170237e-04 4.01776284e-03 4.35246417e-03 9.57591849e-03\n",
      " 4.71844818e-02 1.79089126e-03 1.99309716e-03 5.06378763e-03\n",
      " 4.41413652e-03 6.87333010e-03 9.72464663e-03 7.25506450e-03\n",
      " 5.09032076e-02 5.28410988e-03 1.80831576e-02 7.45880941e-03\n",
      " 1.26359377e-02 2.90289782e-02 4.99960248e-03 7.46086432e-03\n",
      " 1.02392843e-02 2.11320549e-02 8.82964050e-02 1.12426347e-02\n",
      " 9.03650993e-02 8.46398430e-03 8.07402954e-04 3.79537213e-03\n",
      " 8.06455626e-03 3.06029186e-02 1.53103887e-01 1.69883936e-02\n",
      " 1.55382758e-01 2.95620358e-02 4.09003669e-03 3.78338722e-03\n",
      " 2.26515262e-03 7.49169814e-03 1.47513735e-03 1.43027035e-03\n",
      " 5.69072468e-03 7.13443698e-03 2.21235789e-04 1.33556213e-03\n",
      " 1.01889646e-02 1.36105676e-01 3.58570338e-04 2.11329987e-03\n",
      " 4.25440592e-02 4.05864688e-03 3.36792489e-03 6.14811433e-04\n",
      " 7.15486042e-03 1.64297521e-03 2.44856377e-04 1.50431347e-03\n",
      " 1.39794446e-02 1.56164113e-02 3.75060117e-03 4.03472056e-03\n",
      " 2.45000661e-03 1.45267943e-03 1.96419607e-03 1.39189239e-03\n",
      " 1.06284777e-03 2.92879653e-02 4.09944748e-03 3.21003054e-02\n",
      " 2.03808122e-03 2.12790205e-02 3.91994060e-03 1.42056609e-02\n",
      " 4.46427445e-03 5.90209797e-03 1.63844992e-03 5.64834781e-03\n",
      " 9.24706881e-04 1.47465663e-02 3.87235797e-04 3.25147044e-03\n",
      " 3.85752569e-03 8.70547525e-03 5.25671847e-04 3.36240485e-03\n",
      " 9.73725709e-03 7.47411206e-04 1.14582200e-02 1.10462648e-03\n",
      " 2.30423159e-03 3.07079159e-02 8.29244265e-03 9.10618884e-03\n",
      " 9.46880365e-03 3.03606945e-02 1.45640122e-03 6.05722766e-04\n",
      " 7.85073526e-03 3.38728158e-03 2.41965966e-02 2.04103190e-03\n",
      " 6.49674510e-03 8.45584480e-04 1.16076246e-03 9.55679956e-04\n",
      " 5.05967864e-02 2.16173621e-03 2.28246861e-02 1.21571641e-02\n",
      " 4.44730063e-03 6.85940227e-04 1.87085551e-03 1.48199988e-02\n",
      " 3.44713175e-02 5.90863480e-03 1.36931970e-03 3.81226651e-02\n",
      " 6.95565723e-04 1.23208845e-03 1.66309498e-03 1.03460258e-03\n",
      " 4.27446041e-03 4.82794727e-03 7.39860750e-03 4.14353001e-03\n",
      " 1.11043945e-03 3.58139244e-02 2.74660718e-03 8.10184854e-03\n",
      " 1.54776786e-02 2.32144982e-03 4.13953906e-03 1.57880067e-03\n",
      " 1.12601913e-03 1.05328242e-03 4.87318877e-03 3.61417839e-03\n",
      " 2.93575446e-03 1.11003441e-03 2.98096559e-02 1.33944207e-03\n",
      " 3.22111823e-03 7.81021587e-03 9.20589996e-03 2.00425065e-02\n",
      " 6.30037708e-03 1.83676155e-02 1.97353371e-02 7.83572451e-03\n",
      " 2.10914400e-01 2.72281858e-03 7.72923516e-03 1.27725685e-03\n",
      " 1.31880743e-02 6.34609524e-03 5.51541126e-03 8.54731491e-03\n",
      " 4.93512863e-03 1.82312824e-03 3.89913234e-02 1.80375894e-02\n",
      " 4.74877140e-03 1.69598784e-03 1.12756201e-02 8.02493982e-04\n",
      " 3.45296903e-02 9.79946961e-03 1.23412917e-01 2.78999429e-04\n",
      " 2.22844444e-03 2.70235357e-02 2.31399565e-03 1.50408241e-03\n",
      " 2.92675110e-03 1.93830737e-03 2.83814737e-03 1.45424799e-03\n",
      " 7.91672425e-03 1.48539484e-03 2.53345007e-02 1.45552031e-03\n",
      " 1.36656343e-02 2.31477804e-03 5.89879848e-04 9.65067683e-03\n",
      " 8.76211567e-03 1.22347813e-02 7.67001053e-04 2.76604400e-03\n",
      " 2.60053852e-02 2.41717685e-02 1.96793734e-02 5.97154984e-04\n",
      " 2.75999328e-03 3.13684894e-03 6.26523272e-03 9.82497190e-03\n",
      " 2.59390804e-03 2.47767670e-02 3.40433472e-02 1.98281708e-02\n",
      " 9.68035551e-04 2.74579927e-03 2.93266773e-02 2.40957424e-03\n",
      " 4.46176738e-02 9.29305301e-04 1.14869895e-02 5.52120524e-04\n",
      " 3.71817234e-04 5.82232495e-03 4.09947734e-03 4.27303527e-03\n",
      " 8.22446808e-01 1.40043673e-03 2.01677548e-03 2.36207921e-03\n",
      " 4.89446469e-01 2.03097468e-03 1.99340200e-03 1.53506252e-03\n",
      " 3.68012102e-04 5.25737088e-01 5.49435650e-04 4.59504016e-01\n",
      " 1.90869172e-02 2.88570410e-02 7.16037830e-04 6.12052140e-03\n",
      " 9.21301392e-03 4.71236435e-04 8.99033093e-04 5.38689081e-03\n",
      " 1.33579805e-03 7.61870807e-03 1.12541104e-03 3.38008331e-01\n",
      " 3.67475439e-01 1.47433230e-03 2.34456563e-02 3.66772109e-03\n",
      " 6.76161715e-04 4.79746240e-03 6.09491738e-02 1.65898941e-02\n",
      " 6.37555239e-03 6.48131561e-04 1.45033223e-02 6.60068048e-04\n",
      " 1.97983367e-03 1.39786697e-02 5.45787928e-03 1.67535387e-02\n",
      " 1.82939402e-03 1.47624470e-03 5.58611080e-01 3.88326131e-01\n",
      " 3.53173655e-01 8.65734273e-04 2.94065308e-02 6.66698866e-03\n",
      " 8.83153873e-04 1.12758368e-02 9.71929787e-03 2.63934843e-03\n",
      " 5.20223528e-01 8.61394923e-03 7.39289325e-03 1.30113626e-02\n",
      " 3.54091654e-03 3.96874415e-03 9.46141735e-01 8.94776642e-01\n",
      " 7.19070400e-03 1.00278460e-02 1.97749307e-03 3.35260536e-04\n",
      " 2.92299083e-03 2.66495859e-03 1.41165345e-02 9.92048457e-01\n",
      " 5.89198002e-03 8.37749423e-03 1.81304170e-03 5.63656018e-03\n",
      " 4.40852111e-03 5.30182639e-04 5.79317150e-03 1.30190716e-03\n",
      " 3.70725233e-03 9.50078946e-04 9.60238147e-04 1.61042612e-01\n",
      " 4.48859143e-02 1.52926486e-03 1.08096862e-02 1.18205327e-03\n",
      " 3.80282325e-04 4.42761605e-03 8.83519195e-03 1.72621773e-03\n",
      " 3.64904077e-03 2.84957058e-03 5.70121957e-02 2.11323693e-02\n",
      " 1.00151088e-03 5.20619174e-04 6.94569055e-03 2.95658231e-03\n",
      " 3.33907996e-04 4.07649562e-03 3.76099910e-03 7.36867305e-03\n",
      " 6.39391330e-03 1.44863618e-03 2.65332212e-03 3.80878471e-03\n",
      " 3.15423949e-03 3.97168685e-03 2.19399672e-03 2.59343125e-02\n",
      " 7.28467322e-03 2.97908665e-03 7.86259377e-03 1.40822687e-02\n",
      " 2.01220319e-03 3.67311310e-03 3.75244251e-03 7.90848434e-02\n",
      " 5.19780652e-03 1.63052710e-03 3.01945058e-03 3.88083723e-03\n",
      " 3.38209728e-02 4.12443522e-03 3.44136514e-02 4.91793465e-03\n",
      " 2.20473187e-01 7.16787337e-04 3.00504796e-02 2.52296236e-03\n",
      " 4.16533145e-03 7.21035041e-02 7.20339740e-03 5.88237117e-02\n",
      " 1.40096785e-03 1.18390095e-03 5.60905872e-04 8.10662360e-03\n",
      " 4.66406907e-03 8.19709874e-03 5.79543613e-03 5.86769782e-03\n",
      " 2.65068656e-01 1.17016694e-03 4.22471189e-02 3.24547633e-02\n",
      " 5.57597363e-03 2.72661351e-03 1.96514969e-02 6.22640569e-02\n",
      " 2.38093041e-03 6.60514088e-04 6.71753986e-02 1.10190387e-02\n",
      " 4.02632505e-02 2.05614732e-02 3.56349819e-03 1.64717257e-03\n",
      " 3.99593636e-03 6.60577713e-04 1.16506261e-02 9.01417574e-04\n",
      " 1.04830120e-03 1.80873201e-03 4.88158932e-03 4.61086645e-03\n",
      " 2.37143552e-02 5.78311610e-03 1.64245686e-03 8.86501744e-03\n",
      " 1.89874434e-04 3.16271794e-02 4.38411164e-03 1.13795797e-03\n",
      " 1.32349634e-03 3.05890434e-02 1.18782955e-03 4.28562675e-03\n",
      " 2.15490064e-03 5.90734398e-02 8.13301798e-04 2.29144849e-03\n",
      " 3.12909940e-02 3.55718785e-03 2.08359380e-03 9.39463775e-04\n",
      " 5.63955455e-04 2.98768637e-03 1.13982594e-02 7.45312747e-03\n",
      " 1.53713615e-02 6.97980681e-03 8.45244158e-04 5.75693964e-04\n",
      " 1.04407594e-03 2.84879743e-04 1.78726138e-03 2.61326409e-02\n",
      " 5.07097290e-03 1.32789492e-03 4.12873405e-04 1.20053493e-02\n",
      " 3.10422683e-04 1.15395850e-02 8.00244726e-03 1.34537910e-02\n",
      " 6.81339775e-03 1.69195135e-03 1.69571377e-02 5.10907505e-03\n",
      " 1.37529800e-02 3.03626253e-03 2.64454429e-03 4.70405267e-03\n",
      " 1.59843975e-02 7.30535714e-03 2.42748299e-02 2.42910249e-02\n",
      " 2.30833160e-02 1.21646131e-02 1.00295818e-02 5.92491229e-03\n",
      " 3.57391266e-03 1.97675041e-02 5.09598802e-03 3.81005425e-02\n",
      " 5.15958727e-02 1.54437512e-02 9.76835261e-03 6.39349120e-02\n",
      " 5.01207211e-02 5.55054648e-03 3.24138715e-02 4.33261094e-03\n",
      " 8.42023181e-03 6.34755002e-03 5.12074511e-02 4.85693232e-04\n",
      " 1.76943246e-02 1.94497998e-02 5.41118416e-03 2.94129809e-02\n",
      " 1.48779029e-03 5.49789256e-03 1.59245305e-02 1.48178498e-03\n",
      " 2.27720118e-02 2.67489201e-02 3.85653926e-02 1.25852675e-02\n",
      " 3.49856152e-03 1.92139202e-02 1.00806963e-03 4.84483913e-03\n",
      " 6.22752879e-04 3.14754411e-03 7.23729068e-02 1.87868142e-03\n",
      " 4.98494541e-04 9.40064956e-02 4.68028491e-03 2.75160678e-03\n",
      " 7.25125466e-02 1.80488962e-03 2.77566749e-02 1.24561846e-02\n",
      " 1.23316431e-02 2.23314452e-02 2.15979868e-04 6.46265165e-03\n",
      " 3.26290051e-03 3.30526964e-02 1.19771662e-03 3.03558851e-03\n",
      " 8.56759274e-04 9.04180488e-04 1.04046742e-02 5.59000284e-04\n",
      " 5.67621674e-03 2.81783150e-03 2.16983631e-03 4.20792113e-03]\n"
     ]
    }
   ],
   "source": [
    "predict_proba(testdata)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deployment (1).ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad5c119354b5158b483e530ead65be8a1bb28e4331f34b827dc309a6a2790ca5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
